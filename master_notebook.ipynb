{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "from scipy.stats import pearsonr\nfrom skimage.metrics import structural_similarity as ssim\nfrom scipy.fft import fft, fftfreq, rfft, rfftfreq\nfrom sklearn.preprocessing import MinMaxScaler\nfrom scipy.signal import correlate2d\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nimport os\nimport ast\nimport time\nimport pandas as pd\nimport random",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "Matplotlib is building the font cache; this may take a moment.\n"
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "def video_frames_fps(filename):\n    cap = cv2.VideoCapture(filename)\n    return int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), cap.get(cv2.CAP_PROP_FPS) #fps = video.get(cv2.CAP_PROP_FPS)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": "def normalize_list_sklearn(lst):\n    scaler = MinMaxScaler()\n    return scaler.fit_transform([[x] for x in lst]).flatten()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": "def extract_frames(video_path, output_folder):\n    # Ensure the output folder exists\n    os.makedirs(output_folder, exist_ok=True)\n    \n    # Open the video file\n    video = cv2.VideoCapture(video_path)\n    if not video.isOpened():\n        raise ValueError(f\"Error opening video file: {video_path}\")\n    \n    frame_count = 0\n    while True:\n        ret, frame = video.read()\n        if not ret:\n            break\n        \n        # Save the frame as an image file\n        frame_filename = os.path.join(output_folder, f\"frame_{frame_count:04d}.jpg\")\n        cv2.imwrite(frame_filename, frame)\n        \n        frame_count += 1\n    \n    # Release the video capture object\n    video.release()\n    \n    print(f\"Extracted {frame_count} frames to '{output_folder}'\")\n    return frame_count",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": "def compare_images(func, image_path1, image_path2):\n    # Read the images\n    image1 = cv2.imread(image_path1, cv2.IMREAD_GRAYSCALE)\n    image2 = cv2.imread(image_path2, cv2.IMREAD_GRAYSCALE)\n    \n    # Check if images were loaded correctly\n    if image1 is None or image2 is None:\n        raise ValueError(\"One or both image paths are invalid or the images cannot be read.\")\n    \n    # Resize images to the same dimensions, if necessary\n    if image1.shape != image2.shape:\n        image2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]))\n    \n    if func == 'histogram':\n        hist1 = cv2.calcHist([image1], [0], None, [256], [0, 256])\n        hist2 = cv2.calcHist([image2], [0], None, [256], [0, 256])\n        similarity = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n    \n    elif func == 'cor3':\n        # Calculate correlation\n        image1 = image1.flatten()\n        image2 = image2.flatten()\n        similarity = np.corrcoef(image1, image2)[0,1]\n    \n    return similarity",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": "def similarity_Signal(func, reference_frame_number):\n    simSig = []\n    ref_frame_number_str = f\"{reference_frame_number:04d}\"\n    image_path1 = 'Frames/Video_'+video_name+'/frame_' + ref_frame_number_str + '.jpg'\n    for i in range(totalFrames):\n        image_path2 = 'Frames/Video_'+video_name+'/frame_' + f\"{i:04}\" +\".jpg\"\n        \n        simSig.append(compare_images(func,image_path1, image_path2))\n    \n    return simSig",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": "def plot_similarity(sim_metric, y_values, y_range):\n    x = np.linspace(0, totalFrames, totalFrames)\n    y = y_values\n    \n    # Create the plot\n    plt.plot(x, y, label=sim_metric)\n    plt.ylim(y_range[0], y_range[1])\n    \n    # Add labels and title\n    plt.xlabel(\"frame\")\n    plt.ylabel(\"similarity\")\n    plt.title(\"Frames Similarities to frame 0001\")\n    \n    # Add a legend\n    plt.legend()\n    \n    # Show the grid\n    plt.grid()\n    \n    # Display the plot\n    plt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": "def subplot_similarity(subpl, sim_metric, y_values, y_range):\n    x = np.linspace(0, totalFrames, totalFrames)\n    y = y_values\n    \n    # Create the plot\n    plt.subplot(2, 1, subpl)\n    plt.plot(x, y, label=sim_metric)\n    plt.ylim(y_range[0], y_range[1])\n    \n    # Add labels and title\n    plt.xlabel(\"frame\")\n    plt.ylabel(\"similarity\")\n    plt.title(\"Frames Similarities to frame 0001\")\n    \n    # Add a legend\n    plt.legend()\n    \n    # Show the grid\n    plt.grid()\n    \n    # Display the plot\n    plt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": "def second_max_index(arr):\n    # Find the index of the maximum value\n    max_index = np.argmax(arr)\n\n    # Create a copy of the array and set the maximum value to negative infinity\n    arr_copy = np.copy(arr)\n    arr_copy[max_index] = -np.inf\n\n    # Find the index of the second maximum value\n    second_max_index = np.argmax(arr_copy)\n\n    return second_max_index",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": "def find_period(signal):\n    # Sample data\n    x = np.linspace(0, totalFrames, totalFrames)\n    y = signal\n\n    # Calculate FFT\n    yf = fft(y)\n    xf = fftfreq(len(y), x[1] - x[0])\n  \n    # Find the dominant frequency\n    dominant_frequency = xf[second_max_index(np.abs(yf))]\n    \n    # Calculate the period\n    period = 1 / dominant_frequency\n    \n    # Plot the results\n    plt.figure(figsize=(12, 6))\n    \n    plt.subplot(2, 2, 2)\n    plt.plot(x, y)\n    plt.title('Original Signal')\n\n    #xf = np.where(xf >= 0)\n    \n    plt.subplot(2, 2, 1)\n    plt.plot(xf, np.abs(yf))\n    plt.title('FFT')\n    plt.xlabel('Frequency')\n    plt.ylabel('Amplitude')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(\"\\t\\t\\tDominant Frequency: %.3f , Period: %.3f\" %(dominant_frequency, period))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": "def autoCorrelation(signal):\n    fs = totalFrames  # Sampling rate\n    \n    t = np.arange(0, 1, 1/fs) # Time vector\n    t = t[:len(signal)]\n    \n\n    autocorr = np.correlate(signal, signal, mode='full')\n    autocorr = autocorr[len(signal)-1:] # Only take positive lags\n\n    peaks = np.diff(np.sign(np.diff(autocorr))) < 0 # Find local maxima\n    peak_indexes = np.where(peaks)[0] + 1\n    \n    if len(peak_indexes) <= 0:\n        print(\"\\t\\t\\tNo clear period found.\")\n        period = 0\n    else:\n      \n        period = peak_indexes[0] / fs # Period in seconds\n        print(f\"\\t\\tPeriod: {(totalFrames/frame_rate)*period:.3f} seconds\" ,end = \"\")\n        print(f\"\\tPeriod: {totalFrames*period:.3f} frames\") # frame_rate frames / second\n        \n    plt.figure(figsize=(12, 6))\n    plt.subplot(2, 2, 2)\n    plt.plot(t*(totalFrames/frame_rate), signal)\n    plt.title(\"Signal\")\n\n    plt.subplot(2, 2, 1)\n    plt.plot((totalFrames/frame_rate)*np.arange(len(autocorr))/fs, autocorr)\n    plt.title(\"Autocorrelation\")\n    plt.xlabel(\"Lag (seconds)\")\n    plt.scatter((totalFrames/frame_rate)*period, autocorr[int(period*fs)], color='red', marker='o', label=f'Period: {(totalFrames/frame_rate)*period:.3f} s')\n    plt.legend()\n    plt.tight_layout()\n    plt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": "def cepstrumAnalysis(signal):\n    # Define the signal\n    fs = totalFrames  # Sampling frequency\n    \n    t = np.arange(0, 1, 1/fs) # Time vector\n    t = t[:len(signal)]\n    \n    # Calculate the cepstrum\n    spectrum = np.fft.fft(signal)\n    log_spectrum = np.log(np.abs(spectrum))\n    cepstrum = np.fft.ifft(log_spectrum)\n    \n    # Identify the peak\n    cepstrum = np.abs(cepstrum) # Take the absolute value to get the real cepstrum\n    peak_index = np.argmax(cepstrum[3:-3]) + 3 # Exclude first 5 samples\n    \n    # Calculate the period\n    period = peak_index / fs\n    \n    # Plot the signal and the cepstrum\n    plt.figure(figsize=(12, 6))\n    \n    plt.subplot(2, 2, 2)\n    plt.plot((totalFrames/frame_rate)*t, signal)\n    plt.title('Signal')\n    plt.xlabel('Time (s)')\n    plt.ylabel('Amplitude')\n    \n    plt.subplot(2, 2, 1)\n    plt.plot((totalFrames/frame_rate)*np.arange(len(cepstrum))/fs, cepstrum)\n    plt.title('Cepstrum')\n    plt.xlabel('Quefrency (s)')\n    plt.ylabel('Amplitude')\n    plt.axvline(x=(totalFrames/frame_rate)*period, color='r', linestyle='--', label=f'Period = {(totalFrames/frame_rate)*period:.3f} s')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(f\"\\t\\tPeriod: {(totalFrames/frame_rate)*period:.3f} seconds\\tPeriod: {totalFrames*period:.3f} frames\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": "def read_signal_file(file_name):\n    # opening the file in read mode \n    my_file = open(file_name, \"r\")\n\n    data = my_file.read() \n    data_into_list = data.replace(']', ']\\n')\n    data_into_list = data_into_list.replace('np.float64(','(')\n    data_into_list = data_into_list.split('\\n')\n    my_file.close()\n    return data_into_list",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": "def write_signal_file(file_name, reference_frame_number):\n    with open(file_name, 'w') as output:\n      \n        signal = similarity_Signal('histogram', reference_frame_number)\n        output.write(str(signal))\n        \n        signal = similarity_Signal('cor3', reference_frame_number)\n        output.write(str(signal))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": "def reference_frame_analysis(video_name):\n    for ref_frame_num in [0.2*totalFrames, 0.5*totalFrames, 0.8*totalFrames]:\n        ref_frame_num = int(ref_frame_num)\n\n        print('\\n')\n        print(5*'* ' + 'Video: ' + video_name + ' '  + 'Reference frame at: (' + str(round(100*ref_frame_num/totalFrames)) + '%) '+ str(ref_frame_num) + 5*' *')\n        \n        write_signal_file('Signals/Video_' + video_name + '_ref_' + str(ref_frame_num) +'.txt', ref_frame_num)\n        data_into_list = read_signal_file('Signals/Video_' + video_name + '_ref_' + str(ref_frame_num) +'.txt')\n        \n        ls_Histogram = ast.literal_eval(data_into_list[0])\n        ls_PearsonCor2 = ast.literal_eval(data_into_list[1])\n\n        print('\\n Similarity Signal - Histogram \\n')\n        subplot_similarity(1,'Histogram', normalize_list_sklearn(ast.literal_eval(data_into_list[0])), (0,1))\n        print('\\n Similarity Signal - Pearson Correlation \\n')\n        subplot_similarity(1,'Pearson Cor. 2', normalize_list_sklearn(ast.literal_eval(data_into_list[1])), (0,1))\n        \n        print('\\n Histogram - FFT \\n')\n        find_period(ls_Histogram)\n        print('\\n PCC - FFT \\n')\n        find_period(ls_PearsonCor2)\n        \n        print('\\n Histogram - Cepstrum \\n')\n        cepstrumAnalysis(ls_Histogram)\n        print('\\n PCC - Cepstrum \\n')\n        cepstrumAnalysis(ls_PearsonCor2)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 24
    },
    {
      "cell_type": "code",
      "source": "'''\nfor pair in [ ('1','.mp4'),\n              ('2','.mp4'),\n              ('3','.mp4'),\n              ('4','.mp4'),\n              ('5','.mp4'),\n              ('6','.webm'),\n              ('7','.webm'),\n              ('8','.webm'),\n              ('9','.webm'),\n              ('10','.webm'),\n              ('11','.webm'),\n              ('12','.webm'),\n              ('13','.mp4'),\n              ('14','.webm'),\n              ('15','.webm'),\n              ('16','.webm'),\n              ('17','.webm'),\n              ('18','.webm'),\n              ('19','.mp4'),\n              ('20','.mp4'),\n            ]:\n    video_name = pair[0]\n    video_ext = pair[1]\n    totalFrames = extract_frames(video_name+video_ext, 'Frames/Video_'+video_name)\n'''",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#reference_frame_analysis(video_name)",
      "metadata": {
        "trusted": true,
        "tags": [],
        "editable": true,
        "slideshow": {
          "slide_type": ""
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "for pair in [ ('1','.mp4'),\n              ('2','.mp4'),\n              ('3','.mp4'),\n              ('4','.mp4'),\n              ('5','.mp4'),\n              ('6','.webm'),\n              ('7','.webm'),\n              ('8','.webm'),\n              ('9','.webm'),\n              ('10','.webm'),\n              ('11','.webm'),\n              ('12','.webm'),\n              ('13','.mp4'),\n              ('14','.webm'),\n              ('15','.webm'),\n              ('16','.webm'),\n              ('17','.webm'),\n              ('18','.webm'),\n              ('19','.mp4'),\n              ('20','.mp4'),\n            ]:\n    video_name = pair[0]\n    video_ext = pair[1]\n    totalFrames, frame_rate = video_frames_fps(video_name+video_ext)\n\n    print(5*'* ' + video_name + video_ext + f'  Frames:{totalFrames} FPS:{frame_rate}' + 5*' *') \n    \n    reference_frame_analysis(video_name)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# STOP HERE",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": ".autoCorrelation(ls_Histogram)\nautoCorrelation(ls_PearsonCor2)\n\nfind_period(ls_Histogram)\nfind_period(ls_PearsonCor2)\n\ncepstrumAnalysis(ls_Histogram)\ncepstrumAnalysis(ls_PearsonCor2)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}